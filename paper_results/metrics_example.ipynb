{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sssd.utils.visual import (\n",
    "    plot_data,\n",
    "    picp_metic,\n",
    "    nlpd_metric\n",
    ")\n",
    "\n",
    "from properscoring import crps_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"path_to_inference_ouput.pkl\", \"rb\") as input_file:\n",
    "    d = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"rbm\"\n",
    "mr = 0.1\n",
    "N = len(d[mode][mr][\"imputation\"])\n",
    "\n",
    "original = d[\"original\"]\n",
    "observed = original.copy()\n",
    "evaluated = original.copy()\n",
    "\n",
    "missing_mask = d[mode][mr][\"missing_mask\"]\n",
    "observed[missing_mask] = np.nan\n",
    "evaluated[~missing_mask] = np.nan\n",
    "\n",
    "missing_mask = np.array([missing_mask] * N)\n",
    "\n",
    "imputation = d[mode][mr][\"imputation\"]\n",
    "imputation[~missing_mask] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\"mar\", \"bom\", \"rbm\", \"tsf\"]\n",
    "mrs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "mae = pd.DataFrame(columns = modes, index = mrs)\n",
    "mape = pd.DataFrame(columns = modes, index = mrs)\n",
    "rmse = pd.DataFrame(columns = modes, index = mrs)\n",
    "picp = pd.DataFrame(columns = modes, index = mrs)\n",
    "crps = pd.DataFrame(columns = modes, index = mrs)\n",
    "nlpd = pd.DataFrame(columns = modes, index = mrs)\n",
    "\n",
    "original = d[\"original\"]\n",
    "for mode in modes:\n",
    "    for mr in mrs:\n",
    "        missing_mask = d[mode][mr][\"missing_mask\"]\n",
    "        compare_mask = ~np.isnan(original) & missing_mask\n",
    "        missing_mask = np.array([missing_mask] * 5)\n",
    "\n",
    "        imputation = d[mode][mr][\"imputation\"]\n",
    "        imputation[~missing_mask] = np.nan\n",
    "\n",
    "        mae.loc[mr, mode] = mean_absolute_error(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask]\n",
    "        )\n",
    "\n",
    "        w = (original[compare_mask]!=0).astype(float)\n",
    "        w /= w.sum()\n",
    "        mape.loc[mr, mode] = mean_absolute_percentage_error(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask],\n",
    "            sample_weight=w\n",
    "        )\n",
    "\n",
    "        rmse.loc[mr, mode] = np.sqrt(mean_squared_error(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask]\n",
    "        ))\n",
    "\n",
    "        picp.loc[mr, mode] = picp_metic(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask],\n",
    "            np.std(imputation, axis=0)[compare_mask]\n",
    "        )\n",
    "        \n",
    "        crps.loc[mr, mode] = np.mean(crps_gaussian(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask],\n",
    "            np.std(imputation, axis=0)[compare_mask]\n",
    "        ))\n",
    "\n",
    "        nlpd.loc[mr, mode] = nlpd_metric(\n",
    "            original[compare_mask],\n",
    "            np.mean(imputation, axis=0)[compare_mask],\n",
    "            np.std(imputation, axis=0)[compare_mask]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    nrows=3, ncols=2, figsize=(20, 20)\n",
    ")\n",
    "labels = {\n",
    "    \"mar\": \"Missing at random\",\n",
    "    \"bom\": \"Blackout missing\",\n",
    "    \"rbm\": \"Random block missing\",\n",
    "    \"tsf\": \"Forecasting\"\n",
    "}\n",
    "for mode in modes:\n",
    "    axes[0][0].plot(mrs, mae[mode], label=labels[mode])\n",
    "    axes[0][0].set_xlabel(\"Missing Rate\")\n",
    "    axes[0][0].set_ylabel(\"Mean Absolute Error\")\n",
    "    axes[0][0].legend()\n",
    "\n",
    "    axes[0][1].plot(mrs, mape[mode], label=labels[mode])\n",
    "    axes[0][1].set_xlabel(\"Missing Rate\")\n",
    "    axes[0][1].set_ylabel(\"Mean Absolute Percentage Error\")\n",
    "    axes[0][1].legend()\n",
    "\n",
    "    axes[1][0].plot(mrs, rmse[mode], label=labels[mode])\n",
    "    axes[1][0].set_xlabel(\"Missing Rate\")\n",
    "    axes[1][0].set_ylabel(\"Root Mean Squared Error\")\n",
    "    axes[1][0].legend()\n",
    "\n",
    "    axes[1][1].plot(mrs, picp[mode], label=labels[mode])\n",
    "    axes[1][1].set_xlabel(\"Missing Rate\")\n",
    "    axes[1][1].set_ylabel(\"Prediction Interval Coverage Probability\")\n",
    "    axes[1][1].legend()\n",
    "\n",
    "    axes[2][0].plot(mrs, crps[mode], label=labels[mode])\n",
    "    axes[2][0].set_xlabel(\"Missing Rate\")\n",
    "    axes[2][0].set_ylabel(\"Mean Continious Ranked Probability Score\")\n",
    "    axes[2][0].legend()\n",
    "\n",
    "    axes[2][1].plot(mrs, nlpd[mode], label=labels[mode])\n",
    "    axes[2][1].set_xlabel(\"Missing Rate\")\n",
    "    axes[2][1].set_ylabel(\"Mean Negative Log Probabiliti Density\")\n",
    "    axes[2][1].legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
